\documentclass[a4paper,11pt,notitlepage]{report}
% Henrik Lund Kramshoej, February 2001
% hlk@security6.net,
% My standard packages
\usepackage{kea-exercises}

\begin{document}

%\rm
\selectlanguage{english}

\newcommand{\emne}[1]{Intro to IT-security Systems Security workshop}
\newcommand{\kursus}[1]{Computer Systems Security workshop}
\newcommand{\kursusnavn}[1]{Computer Systems Security workshop\\ exercises}

\mytitle{Systems Security Exercises}{Intro to IT-security \the\year}

\setcounter{tocdepth}{0}


\normal

{\color{titlecolor}\tableofcontents}
%\listoffigures - not used
%\listoftables - not used

\normal
\pagestyle{fancyplain}
\chapter*{\color{titlecolor}Preface}
\markboth{Preface}{}

This material is prepared for use in courses and was prepared by
Henrik Kramselund, \link{http://www.zencurity.com} .
It describes the networking setup and
applications for trainings and workshops where hands-on exercises are needed.

\vskip 1cm
Further a presentation is used which is available as PDF from kramse@Github\\
Look for \jobname in the repo security-courses.

These exercises are expected to be performed in a training setting with network connected systems. The exercises use a number of tools which can be copied and reused after training. A lot is described about setting up your workstation in the repo

\link{https://github.com/kramse/kramse-labs}


\section*{\color{titlecolor}Prerequisites}

This material expect that participants have a working knowledge of
TCP/IP from a user perspective. Basic concepts such as web site addresses and email should be known as well as IP-addresses and common protocols like DHCP.

\vskip 1cm
Have fun and learn
\eject

% =================== body of the document ===============
% Arabic page numbers
\pagenumbering{arabic}
\rhead{\fancyplain{}{\bf \chaptername\ \thechapter}}

% Main chapters
%---------------------------------------------------------------------
% gennemgang af emnet
% check questions

\chapter*{\color{titlecolor}Exercise content}
\markboth{Exercise content}{}

Most exercises follow the same procedure and has the following content:
\begin{itemize}
\item {\bf Objective:} What is the exercise about, the objective
\item {\bf Purpose:} What is to be the expected outcome and goal of doing this exercise
\item {\bf Suggested method:} suggest a way to get started
\item {\bf Hints:} one or more hints and tips or even description how to
do the actual exercises
\item {\bf Solution:} one possible solution is specified
\item {\bf Discussion:} Further things to note about the exercises, things to remember and discuss
\end{itemize}

Please note that the method and contents are similar to real life scenarios and does not detail every step of doing the exercises. Entering commands directly from a book only teaches typing, while the exercises are designed to help you become able to learn and actually research solutions.




\chapter{\faInfoCircle\ Mitre ATT\&CK Framework 15min}
\label{ex:mitre-attack}


\hlkimage{14cm}{mitre-attack.png}

Source:  Great resource for attack categorization



{\bf Objective:}\\
See examples of attack methods used by real actors.


{\bf Purpose:}\\
When analyzing incidents we often need to understand how they gained acccess, moved inside the network, what they did to escalate privileges and finally exfiltrate data.

{\bf Suggested method:}\\
Go to the web site \url{https://attack.mitre.org/}, browse the matrix and read a bit here and there.

Browse the ATT\&CK 101 Blog Post\\
\url{https://medium.com/mitre-attack/att-ck-101-17074d3bc62}


{\bf Hints:}\\
The columns can be thought of as a progression. An attacker might perform recon first, then gain initial access etc. all the way to the right most columns.

{\bf Solution:}\\
When you have researched a few details in the model you are done.

{\bf Discussion:}\\
This is a large model which evolved over many years. You are not expected to remember it all, or understand it all.


\chapter{\faInfoCircle\ Download Debian Administrator’s Handbook (DEB) Book 10min}
\label{ex:sw-downloadDEB}

\hlkimage{3cm}{book-debian-administrators-handbook.jpg}


{\bf Objective:}\\
We need a Linux for running some tools during the course. I have chosen Debian Linux as this is open source, and the developers have released a whole book about running it.

This book is named
\emph{The Debian Administrator’s Handbook},  - shortened DEB

{\bf Purpose:}\\
We need to install Debian Linux in a few moments, so better have the instructions ready.

{\bf Suggested method:}\\
Create folders for educational materials. Go to download from the link \url{https://debian-handbook.info/}
Read and follow the instructions for downloading the book.

{\bf Solution:}\\
When you have a directory structure for download for this course, and the book DEB in PDF you are done.

{\bf Discussion:}\\
Linux is free and everywhere. The tools we will run in this course are made for Unix, so they run great on Linux.

Debian Linux is a free operating system platform.

The book DEB is free, but you can buy/donate to Debian, and I recommend it.

Not curriculum but explains how to use Debian Linux




\chapter{\faExclamationTriangle\ Check your Debian VM 10min}
\label{ex:basicDebianVM}

\hlkimage{3cm}{debian-xfce.png}

{\bf Objective:}\\
Make sure your Debian virtual machine is in working order.

We need a Debian 11 Linux for running a few extra tools during the course.


{\bf Purpose:}\\
If your VM is not installed and updated we will run into trouble later.

{\bf Suggested method:}\\
Go to \link{https://github.com/kramse/kramse-labs/}

Read the instructions for the setup of a Debian VM.

{\bf Hints:}\\

{\bf Solution:}\\
When you have a updated Debian Linux, then we are good.

{\bf Discussion:}\\
Linux is free and everywhere. The tools we will run in this course are made for Unix, so they run great on Linux.



\chapter{\faExclamationTriangle\ Investigate /etc 10min}
\label{ex:basicLinuxetc}


{\bf Objective:}\\
We will investigate the /etc directory on Linux

We need a Kali Linux and a Debian Linux VM, to compare


{\bf Purpose:}\\
Start seeing example configuration files, including:
\begin{itemize}
  \item User database \verb+/etc/passwd+ and \verb+/etc/group+
  \item The password database \verb+/etc/shadow+
\end{itemize}

{\bf Suggested method:}\\
Boot your Linux VMs, log in

Investigate permissions for the user database files \verb+passwd+ and \verb+shadow+

{\bf Hints:}\\
Linux has many tools for viewing files, the most efficient would be less.

\begin{alltt}
hlk@debian:~$ cd /etc
hlk@debian:/etc$ ls -l shadow passwd
-rw-r--r-- 1 root root   2203 Mar 26 17:27 passwd
-rw-r----- 1 root shadow 1250 Mar 26 17:27 shadow
hlk@debian:/etc$ ls
... all files and directories shown, investigate more if you like
\end{alltt}

Showing a single file: \verb+less /etc/passwd+ and press q to quit

Showing multiple files: \verb+less /etc/*+ then :n for next and q for quit

\begin{alltt}
Trying reading the shadow file as your regular user:
user@debian-9-lab:/etc$ cat /etc/shadow
cat: /etc/shadow: Permission denied
\end{alltt}

Why is that? Try switching to root, using su or sudo, and redo the command.

{\bf Solution:}\\
When you have seen the most basic files you are done.

{\bf Discussion:}\\
Linux is free and everywhere. The tools we will run in this course are made for Unix, so they run great on Linux.




\chapter{\faExclamationTriangle\ Enable UFW firewall - 10min}
\label{ex:debian-firewall}

\hlkimage{12cm}{2048px-Eilan_Donan_Castle_Entrance.jpg}

Source: Picture is Eilean Donan castle entrance\\
\verb+2048px-Eilan_Donan_Castle_Entrance.jpg+ from \url{https://en.wikipedia.org/wiki/Eilean_Donan}

{\bf Objective:}\\
Turn on a firewall and configure a few simple rules.

{\bf Purpose:}\\
See how easy it is to restrict incoming connections to a server.


{\bf Suggested method:}\\
Install a utility for firewall configuration.

You could also perform Nmap port scan with the firewall enabled and disabled.

{\bf Hints:}\\
Using the ufw package it is very easy to configure the firewall on Linux.

Install and configuration can be done using these commands.
\begin{alltt}
root@debian01:~# apt install ufw
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following NEW packages will be installed:
  ufw
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 164 kB of archives.
After this operation, 848 kB of additional disk space will be used.
Get:1 http://mirrors.dotsrc.org/debian stretch/main amd64 ufw all 0.35-4 [164 kB]
Fetched 164 kB in 2s (60.2 kB/s)
...
root@debian01:~# ufw allow 22/tcp
Rules updated
Rules updated (v6)
root@debian01:~# ufw enable
Command may disrupt existing ssh connections. Proceed with operation (y|n)? y
Firewall is active and enabled on system startup
root@debian01:~# ufw status numbered
Status: active

     To                         Action      From
     --                         ------      ----
[ 1] 22/tcp                     ALLOW IN    Anywhere
[ 2] 22/tcp (v6)                ALLOW IN    Anywhere (v6)
\end{alltt}

Also allow port 80/tcp and port 443/tcp - and install a web server. Recommend Nginx \verb+apt-get install nginx+

{\bf Solution:}\\
When firewall is enabled and you can still connect to Secure Shell (SSH) and web service, you are done.

{\bf Discussion:}\\
Further configuration would often require adding source prefixes which are allowed to connect to specific services. If this was a database server the database service should probably not be reachable from all of the Internet.

Web interfaces also exist, but are more suited for a centralized firewall.

Configuration of this firewall can be done using ansible, see the documentation and examples at \url{https://docs.ansible.com/ansible/latest/modules/ufw_module.html}

Should you have both a centralized firewall in front of servers, and local firewall on each server? Discuss within your team.


\chapter{\faInfoCircle\ Git tutorials - 15min}
\label{ex:git-tutorial}


\hlkimage{3cm}{git-logo.png}

{\bf Objective:}\\
Try the program Git locally on your workstation

{\bf Purpose:}\\
Running Git will allow you to clone repositories from others easily. This is a great way to get new software packages, and share your own.

Git is the name of the tool, and Github is a popular site for hosting git repositories.

{\bf Suggested method:}\\
Run the program from your Linux VM. You can also clone from your Windows or Mac OS X computer. Multiple graphical front-end programs exist too.


First make sure your system is updated, as root run:

\begin{minted}[fontsize=\footnotesize]{shell}
sudo apt-get update && apt-get -y upgrade && apt-get -y dist-upgrade
\end{minted}
You should reboot if the kernel is upgraded :-)

Second make sure your system has Git, ansible and my playbooks: (as root run, or with sudo as shown)
\begin{minted}[fontsize=\footnotesize]{shell}
sudo apt -y install ansible git
\end{minted}


Most important are Git clone and pull:
\begin{alltt}\footnotesize
user@Projects:tt$ {\bf git clone https://github.com/kramse/kramse-labs.git}
Cloning into 'kramse-labs'...
remote: Enumerating objects: 283, done.
remote: Total 283 (delta 0), reused 0 (delta 0), pack-reused 283
Receiving objects: 100% (283/283), 215.04 KiB | 898.00 KiB/s, done.
Resolving deltas: 100% (145/145), done.

user@Projects:tt$ {\bf cd kramse-labs/}

user@Projects:kramse-labs$ {\bf ls}
LICENSE  README.md  core-net-lab  lab-network  suricatazeek  work-station
user@Projects:kramse-labs$ git pull
Already up to date.
\end{alltt}

If you want to install the Docker system, you can run the Ansible playbook from the directory named docker-install.

Then run it with:
\begin{minted}[fontsize=\footnotesize]{shell}
cd ~/kramse-labs/docker-install
ansible-playbook -v 1-dependencies
\end{minted}



{\bf Hints:}\\
Browse the Git tutorials on \link{https://git-scm.com/docs/gittutorial}\\
and \link{https://guides.github.com/activities/hello-world/}

We will not do the whole tutorials within 15 minutes, but get an idea of the command line, and see examples. Refer back to these tutorials when needed or do them at home.

Note: you don't need an account on Github to download/clone repositories, but having an acccount allows you to save repositories yourself and is recommended.

{\bf Solution:}\\
When you have tried the tool and seen the tutorials you are done.

{\bf Discussion:}\\
Before Git there has been a range of version control systems,\\
see \link{https://en.wikipedia.org/wiki/Version\_control} for more details.




\chapter{\faExclamationTriangle\ Discover active systems ping and port sweep 15min}
\label{ex:nmap-pingsweep}
\hlkimage{4cm}{nmap-zenmap.png}

{\bf Objective:}\\
Use nmap to discover active systems and ports

{\bf Purpose:}\\
Know how to use nmap to scan networks for active systems. These ports receive traffic from \emph{the internet} and can be used for DDoS attacks.

Tip: Yes, filtering traffic further out removes it from processing in routers, firewalls, load balancers, etc. So making a stateless filter on the edge may be recommended.

{\bf Suggested method:}\\
Install Nmap on your Debian VM, \verb+apt install nmap+ . Try different scans:
\begin{itemize}
\item Ping sweep to find active systems
\item Port sweeps to find active systems with specific ports
\end{itemize}

{\bf Use the prefixes and IP addresses handed out by the instructor! They may be different from the ones below!}

{\bf Hints:} \\
Try nmap in sweep mode

{\bf Solution:}\\
Use the command below as examples:
\begin{itemize}
\item Ping sweep ICMP and port probes: \verb+nmap -sP 10.0.45.*+
\item Port sweeps 80/tcp and 443/tcp: \verb+nmap -p 80 10.0.45.*+
\item Port sweeps UDP scans can be done: \verb+nmap -sU -p 161 10.0.45.*+
\end{itemize}

{\bf Discussion:}\\
Quick scans quickly reveal interesting hosts, ports and services

Also now make sure you understand difference between single host scan
10.0.45.123/32, a whole subnet /24 ~250 hosts 10.0.45.0/24 and other more advanced targeteting like 10.0.45.0/25 and 10.0.45.1-10

We will now assume port 80/443 are open, as well as a few UDP services - maybe we can use them in amplification attacks later.


\chapter{\faExclamationTriangle\ Execute nmap TCP and UDP port scan 15min}
\label{ex:nmap-synscan}

\hlkimage{3cm}{tcp-three-way.jpg}

{\bf Objective:} \\
Use nmap to discover important open ports on active systems

{\bf Purpose:}\\
Finding open ports will allow you to find vulnerabilities on these ports.

{\bf Suggested method:}\\
Use \verb+nmap -p 1-1024 server+ to scan the first 1024 TCP
ports and use Nmap without ports. What is scanned then?

Try to use \verb+nmap -sU+ to scan using UDP ports, not really possible if a firewall is in place.

If a firewall blocks ICMP you might need to add \verb+-Pn+ to make nmap scan even if there are no Ping responses

{\bf Hints:} \\
Sample command: \verb+nmap -Pn -sU -p1-1024 server+ UDP port scanning
1024 ports without doing a Ping first

{\bf Solution:}\\
Discover some active systems and most interesting ports, which are 1-1024 and the built-in list of popular ports.

{\bf Discussion:}\\
There is a lot of documentation about the nmap portscanner, even a book by the author
of nmap. Make sure to visit \link{http://www.nmap.org}

TCP and UDP is very different when scanning. TCP is connection/flow oriented and requires a handshake which is very easy to identify. UDP does not have a handshake and most applications will not respond to probes from nmap. If there is no firewall the operating system will respond to UDP probes on closed ports - and the ones that do not respond must be open.

When doing UDP scan on the internet you will almost never get a response, so you cannot tell open (not responding services) from blocked ports (firewall drop packets). Instead try using specific service programs for the services, sample program could be \verb+nsping+ which sends DNS packets, and will often get a response from a DNS server running on UDP port 53.




\chapter{\faExclamationTriangle\ Perform nmap OS detection 15min}
\label{ex:nmap-os}

{\bf Objective:} \\
Use nmap OS detection and see if you can guess the brand of devices on the network

{\bf Purpose:}\\
Getting the operating system of a system will allow you to focus your next attacks. Use more advanced features in Nmap to discover services.

{\bf Suggested method:}\\
Look at the list of active systems, or do a ping sweep.

Then add the OS detection using the option \verb+-O+

Better to use -A all the time, includes even more scripts and advanced stuff
See the next exercise.

{\bf Hints:} \\
The nmap can send a lot of packets that will get different responses, depending on the operating system. TCP/IP is implemented using various constants chosen by the implementors, they have chosen different standard packet TTL etc.

Getting more intimate with the system will allow more precise discovery of the vulnerabilities and also allow you to select the next tools to run.

{\bf Solution:}\\
Use a command like \verb+nmap -O -p1-100 10.0.45.45+ or  \verb+nmap -A -p1-100 10.0.45.45+

Use \verb+nmap -A+ option for enabling service detection and scripts

{\bf Discussion:}\\
nmap OS detection is not a full proof way of knowing the actual operating system, but in most cases in can detect the family and in some cases it can identify the exact patch level of the system.

Some services will show software versions allowing an attacker easy lookup at web sites to known vulnerabilities and often exploits that will have a high probability of success.

Make sure you know the difference between a vulnerability which is discovered, but not really there, a false positive, and a vulnerability not found due to limitations in the testing tool/method, a false negative.

A sample false positive might be reporting that a Windows server has a vulnerability that you know only to exist in Unix systems.


\chapter{\faInfoCircle\ Nmap full scan - 15min}
\label{ex:nmap-strategy}


{\bf Objective:} \\
Documenting the security level of a network often requires extensive testing. Below are some examples of the scanning methodology needed.


{\bf Purpose:}\\
Doing a port scan often requires you to run multiple Nmap scans.


{\bf Suggested method:}\\
Use Zenmap to do:
\begin{enumerate}
\item A few quick scans, to get web servers and start web scanners/crawlers
\item Full scan of all TCP ports, -p 1-65535
\item Full or limited UDP scan, \verb+nmap -sU --top-ports 100+
\item Specialized scans, like specific source ports
\end{enumerate}


{\bf Hints:} \\
Using a specific source ports using -g/--source-port <portnum>: Use given port number with ports like FTP 20, DNS 53 can sometimes get around router filters and other stateless Access Control Lists

{\bf Solution:}\\
Run multiple nmap and get results. At least TCP and UDP top-ports 10.

{\bf Discussion:}\\
Recommendation it is highly recommended to always use:
\begin{alltt}
-iL <inputfilename>: Input from list of hosts/networks
-oA outputbasename: output in all formats, see later
\end{alltt}

Some examples of real life Nmaps I have run recently:
\begin{alltt}
dns-scan: nmap -sU -p 53 --script=dns-recursion -iL targets -oA dns-recursive
bgpscan: nmap -A -p 179 -oA bgpscan -iL targets
dns-recursive: nmap -sU -p 53 --script=dns-recursion -iL targets -oA dns-recursive
php-scan: nmap -sV --script=http-php-version -p80,443 -oA php-scan -iL targets
scan-vtep-tcp: nmap -A -p 1-65535 -oA scan-vtep-tcp 10.1.2.3 192.0.2.123
snmp-10.x.y.0.gnmap: nmap -sV -A -p 161 -sU --script=snmp-info -oA snmp-10xy 10.x.y.0/19
snmpscan: nmap -sU -p 161 -oA snmpscan --script=snmp-interfaces -iL targets
sshscan: nmap -A -p 22 -oA sshscan -iL targets
vncscan: nmap -A -p 5900-5905 -oA vncscan -iL targets
\end{alltt}




\chapter{\faInfoCircle\ Reporting Nmap HTML 10min}
\label{ex:nmap-html}

\hlkimage{10cm}{nmap-html.png}

{\bf Objective:} \\
Show the use of XML output and convert to HTML

{\bf Purpose:}\\
Reporting data is very important. Using the oA option Nmap can export data in three formats easily, each have their use. They are normal, XML, and grepable formats at once.

{\bf Suggested method:}\\
\begin{alltt}
  sudo nmap -oA zencurity-web www.zencurity.com
  xsltproc zencurity-web.xml > zencurity-web.html
\end{alltt}

{\bf Hints:} \\
Nmap includes the stylesheet in XML and makes it very easy to create HTML.

{\bf Solution:}\\
Run XML through xsltproc, command line XSLT processor, or another tool

{\bf Discussion:}\\

Options you can use to change defaults:
\begin{alltt}
--stylesheet <path/URL>: XSL stylesheet to transform XML output to HTML
--webxml: Reference stylesheet from Nmap.Org for more portable XML
\end{alltt}

Also check out the Ndiff tool
\begin{alltt}
  hlk@cornerstone03:~$ ndiff zencurity-web.xml zencurity-web-2.xml
  -Nmap 7.70 scan initiated Fri Sep 07 18:35:54 2018 as: nmap -oA zencurity-web www.zencurity.com
  +Nmap 7.70 scan initiated Fri Sep 07 18:46:01 2018 as: nmap -oA zencurity-web-2 www.zencurity.com

   www.zencurity.com (185.129.60.130):
   PORT    STATE SERVICE VERSION
  +443/tcp open  https
\end{alltt}

(I ran a scan, removed a port from the first XML file and re-scanned)




\chapter{\faInfoCircle\ Nmap Scripting Engine NSE scripts 20min}
\label{ex:nmap-nse}

{\bf Objective:} \\
Show the use of NSE scripts, copy/modify a script written in Lua.

{\bf Purpose:}\\
Investigate the scripts from Nmap, copy one, learn how to run specific script using options

{\bf Suggested method:}\\
\begin{alltt}
# cd /usr/share/nmap/scripts
# nmap --script http-default-accounts.nse www.zencurity.com
# cp http-default-accounts.nse http-default-accounts2.nse
# nmap --script http-default-accounts2.nse www.zencurity.com
Starting Nmap 7.70 ( https://nmap.org ) at 2018-09-07 19:45 CEST
...
\end{alltt}

This will allow you to make changes to existing scripts.

{\bf Hints:} \\
We will do this quick and dirty - later when doing this at home, I recommend putting your scripts in your home directory or a common file hierarchy.

{\bf Solution:}\\
Other examples
\begin{alltt}
nmap --script http-enum 10.0.45.0/24
nmap -p 445 --script smb-os-discovery 10.0.45.0/24
\end{alltt}


{\bf Discussion:}\\
There are often new scripts when new vulnerabilities are published. It is important to learn how to incorporate them into your scanning. When heartbleed roamed I was able to scan about 20.000 IPs for Heartbleed in less than 10 minutes, which enabled us to update our network quickly for this vulnerability.

It is also possible to run categories of scripts:

\begin{alltt}
nmap --script "http-*"

		   nmap --script "default or safe"
			   This is functionally equivalent to nmap --script "default,safe". It loads all scripts that are in the default category or the safe category or both.

		   nmap --script "default and safe"
			   Loads those scripts that are in both the default and safe categories.
\end{alltt}

or get help for a script:

\begin{alltt}
# nmap -script-help http-vuln-cve2013-0156.nse
Starting Nmap 7.70 ( https://nmap.org ) at 2018-09-07 19:00 CEST

http-vuln-cve2013-0156
Categories: exploit vuln
https://nmap.org/nsedoc/scripts/http-vuln-cve2013-0156.html
  Detects Ruby on Rails servers vulnerable to object injection, remote command
  executions and denial of service attacks. (CVE-2013-0156)

  All Ruby on Rails versions before 2.3.15, 3.0.x before 3.0.19, 3.1.x before
  3.1.10, and 3.2.x before 3.2.11 are vulnerable. This script sends 3 harmless
  YAML payloads to detect vulnerable installations. If the malformed object
  receives a status 500 response, the server is processing YAML objects and
  therefore is likely vulnerable.

  References:
  * https://community.rapid7.com/community/metasploit/blog/2013/01/10/exploiting-ruby-on-rails-with-metasploit-cve-2013-0156',
  * https://groups.google.com/forum/?fromgroups=#!msg/rubyonrails-security/61bkgvnSGTQ/nehwjA8tQ8EJ',
  * http://cvedetails.com/cve/2013-0156/
\end{alltt}

Some scripts also require, or allow arguments into them:

\begin{alltt}
  nmap -sC --script-args 'user=foo,pass=",{}=bar",paths={/admin,/cgi-bin},xmpp-info.server_name=localhost'
\end{alltt}


\end{document}




\chapter{\faExclamationTriangle\ Configure a Database - 20 min}
\label{ex:mariadb-createdb}


{\bf Objective:}\\
Try creating a database and add a few users. We will use MariaDB as an example. You can read more about MariaDB at \link{https://mariadb.org/}


{\bf Purpose:}\\
Show that creating a database is very easy, and adding a new user cost literally nothing.

So why aren't more developers concerned with security, least privilege, creating read-only users etc.

{\bf Suggested method:}\\
Get an overview of the LibreNMS install instructions located at:\\
\link{https://docs.librenms.org/Installation/Install-LibreNMS/}

We are running Debian 11, and since we only need to play with the database, only install that part:

\begin{alltt}
apt install mariadb-client mariadb-server
\end{alltt}

and follow only the instructions in \emph{Configure MariaDB} -- the ones with Debian 11!

Repeated here for completeness, but \verb+vi+ changed into \emph{edit}.

{\bf Configure MariaDB -- Debian 11}

Edit \verb+/etc/mysql/mariadb.conf.d/50-server.cnf+

Within the [mysqld] section add:

\begin{alltt}
innodb_file_per_table=1
lower_case_table_names=0
\end{alltt}

Start the database
\begin{alltt}
systemctl enable mariadb
systemctl restart mariadb
\end{alltt}

As root run the database client program \verb+mysql+
\begin{alltt}
mysql -u root
\end{alltt}

NOTE: Change the 'password' below to something secure.

Add a user for the system:
\begin{alltt}
CREATE DATABASE librenms CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER 'librenms'@'localhost' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON librenms.* TO 'librenms'@'localhost';
FLUSH PRIVILEGES;
exit
\end{alltt}

Add another user, with read only:
\begin{alltt}
CREATE USER 'my_readonly'@'localhost' IDENTIFIED BY 'secret_password';
GRANT SELECT ON librenms.* TO 'my_readonly'@'localhost';
FLUSH PRIVILEGES;
\end{alltt}

Such a user would be able to see into the database, fetch statistics etc.

{\bf Solution:}\\
When you have a running database with two users, you are done.


{\bf Discussion:}\\
Lots of systems need \emph{access to data}, but if noone ask -- what permissions, we often default to read AND write. We should default to read-only.



\chapter{\faExclamationTriangle\ RBAC Access permissions on GitHub 30-45min}
\label{ex:github-perms}

{\bf Objective:}\\
See actual real life example of permissions.

Note: This exercise requires a GitHub account, so make sure your group has one. Maybe do groups of 3-4 for more discussion.

{\bf Purpose:}\\
GitHub is a very popular code sharing site.

{\bf Suggested method:}\\
Go to GitHub web page:\\
\link{https://help.github.com/en/articles/access-permissions-on-github}

Follow links to other pages, like:\\
\link{https://help.github.com/en/articles/permission-levels-for-an-organization}


{\bf Hints:}\\
Some might already have an account on GitHub - maybe work through adding a repository and adding collaborators.

If you have an organisation, even better.

{\bf Solution:}\\
When you have discussed GitHub permissions and played with a repository you are done.

{\bf Discussion:}\\
The internet is decentralized, but recent years see more centralization - GitHub, DNS Google DNS, Cloudflare.

What are some problems in this?




\chapter{\faExclamationTriangle\ Password Cracking 15min}
\label{ex:pwcrack-101}

{\bf Objective:}\\
Crack your own passwords using John the Ripper


{\bf Purpose:}\\
See how fast hashes from bad algorithms can be cracked, and how new ones are slow to crack.

{\bf Suggested method:}\\
John the Ripper is available from the web page, but also as a package:\\
\url{https://www.openwall.com/john/}

You should install from the package system using apt install, do apt search first to find the package name.

\begin{enumerate}
\item Install John, if not already there
\item Copy the local password database, as root: \verb+cp /etc/shadow /root/mypasswords+
\item Start cracking: \verb+john --single /root/mypasswords+
\item Restart with incremental mode, bruteforce: \verb+john --incremental /root/mypasswords+
\end{enumerate}

You can make it easier if you add a few users with bad passwords first.

{\bf Hints:}\\
You can download other sample hashes from\\
 \url{https://hashcat.net/wiki/doku.php?id=example_hashes}



{\bf Solution:}\\
When you have cracked at least one password then you are done.

{\bf Discussion:}\\
A better tool might be hashcat, found at:\\
\link{http://hashcat.net/wiki/}

This tool can be used with GPUs Graphical Processing Units / graphic cards for more speed.

Still I find John is often sufficient to crack bad passwords, and also for verification purposes it works great.


\chapter{\faInfoCircle\ Configure SSH keys for more secure access 30min}
\label{ex:config-ssh-keys}

\hlkimage{10cm}{openssh-banner.png}

{\bf Objective:}\\
See how SSH keys can be used.

{\bf Purpose:}\\
Secure Shell is a very powerful administration tool. Administrators use this for managing systems. If an attacker gains access they can perform the same tasks.

Using SSH keys for access and disabling password based logins effectively prevents brute-force login attacks from succeeding.

{\bf Suggested method:}\\

\begin{enumerate}
\item First generate a SSH key, using \verb+ssh-keygen+
\item Copy the public key onto a system, using \verb+ssh-copy-id+
\item Test using the ssh command
\end{enumerate}

Generate key:
\begin{alltt}
\$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Created directory '/root/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/hlk/.ssh/id_rsa.
Your public key has been saved in /home/hlk/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:l5esp66lQArFOlXqOoHnxpg8zRS6shK8nx9KGf+oSp4 root@debian01
The key's randomart image is:
+---[RSA 2048]----+
|      .          |
|   . o           |
|   .=            |
| ..=.      o .   |
|o.*o. . S o +    |
|oB==+o   . o     |
|+*B=.o.   o .    |
|=++.o +. o o     |
|oEo=oo .ooo      |
+----[SHA256]-----+
\end{alltt}

Then use the utility tool \verb+ssh-copy-id+ for copying the public key to the server. Install tool if not available using \verb+apt+ :
\begin{alltt}
\$ ssh-copy-id -i /home/hlk/.ssh/id_rsa hlk@10.0.42.147
/usr/local/bin/ssh-copy-id: INFO: Source of key(s) to be installed: ".ssh/kramse.pub"
The authenticity of host '10.0.42.147 (10.0.42.147)' can't be established.
ECDSA key fingerprint is SHA256:DP6jqadDWEJW/3FYPY84cpTKmEW7XoQ4zDNf/RdTu6M.
Are you sure you want to continue connecting (yes/no)? yes
/usr/local/bin/ssh-copy-id: INFO: attempting to log in with the new key(s),
to filter out any that are already installed
/usr/local/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you
are prompted now it is to install the new keys
hlk@10.0.42.147's password:

Number of key(s) added:        1

Now try logging into the machine, with:   "ssh -o 'IdentitiesOnly yes' 'hlk@10.0.42.147'"
and check to make sure that only the key(s) you wanted were added.
\end{alltt}

\vskip 5mm

\centerline{This is the best tool for the job!}

The public must exist in the \verb+authorized_keys+ file, in the right directory, with the correct permissions ... use \verb+ssh-copy-id+

{\bf Hints:}\\
You can publish the public part of your SSH keys in places such as Github and Ubuntu installation can fetch this during install, making the use of SSH keys extremely easy.

You can add keys to memory, allowing you to enter a passphrase at the beginning of the session, but no passphrases or passwords after:

\begin{alltt}
\$ ssh-add .ssh/kramse
// Passphrase here
Identity added: .ssh/kramse (.ssh/kramse)
\$ ssh-add -l
4096 SHA256:YsR+HhK7u7045ZL8ZDZnlgEnrv+RQG4eJI5oBJAEacs .ssh/kramse (RSA)
\end{alltt}


{\bf Solution:}\\
When you can login using key you are done.

{\bf Discussion:}\\
We have not discussed using passphrase on the key, neither how to turn off password based logins by reconfiguring the SSH daemon. This is left as an exercise for the reader.

You should remove the possibility for root logins and logins using password, when keys work!

This is done editing the file \verb+/etc/ssh/sshd_config+ and the options:
\begin{alltt}
#PermitRootLogin prohibit-password
PermitRootLogin no
# To disable tunneled clear text passwords, change to no here!
PasswordAuthentication no
\end{alltt}



\chapter{\faExclamationTriangle\ CIS Benchmarks teaser 30min}
\label{ex:CIS-benchmarks-teaser}

{\bf Objective:}\\
Checkout CIS benchmarks

{\bf Purpose:}\\
We have talked about operating system security, starting with user accounts on Linux. There are much more to security than users, and there are multiple tools available. One such framework is the Center for Internet Security (CIS) Benchmarks.

Their benchmarks are also implemented in multiple tools, which can help automate checking of the settings.

We will now take a quick look at the CIS benchmarks, and more benchmarking will be discussed later.

{\bf Suggested method:}\\
Choose your operating system/solution and check out at least the general CIS benchmark description and a specific one.

Main site \url{https://www.cisecurity.org/} and some example benchmarks, suggestions:

\begin{list2}
\item Microsoft Windows Server   \url{https://www.cisecurity.org/benchmark/microsoft_windows_server}
\item Microsoft Azure https://www.cisecurity.org/benchmark/azure
\item Azure Linux \url{https://www.cisecurity.org/benchmark/azure_linux}
\item Debian Linux \url{https://www.cisecurity.org/benchmark/debian_linux}
\item Kubernetes \url{https://www.cisecurity.org/benchmark/kubernetes}
\end{list2}

{\bf Hints:}\\
Center for Internet Security (CIS) Benchmarks are also available for Windows, so checkout their offerings:

\url{https://learn.microsoft.com/en-us/compliance/regulatory/offering-cis-benchmark}


{\bf Solution:}\\
When you have seen the CIS web site, read about a specific benchmark you are done.


{\bf Discussion:}\\
We will discuss other tools in class.



\chapter{\faInfoCircle\ Example Policies up to 25min}
\label{ex:example-AUP}

{\bf Objective:}\\
See real world high level policies and discuss where to start. There is no need to re-invent the wheel over and over. Re-use things already made!

{\bf Purpose:}\\
When writing your first policy it may be hard to know what to include. Starting from an example is often easier.

{\bf Suggested method:}\\
Find your AUP for the ISPs we use, you use, your company uses.

{\bf Hints:}\\
Policies for different environments are often very different in scope and goals.

\begin{quote}
SANS, for example, publishes a list of template policies that you can edit for your own
needs. At the time of writing, its list of topics are:
\begin{list2}
\item Acceptable Encryption Policy
\item Acceptable Use Policy
\item Clean Desk Policy
\item Disaster Recovery Plan Policy
\item Digital Signature Acceptance Policy
\item Email Policy
\item Ethics Policy
\item Pandemic Response Planning Policy
\item Password Construction Guidelines
\item Password Protection Policy
\item Security Response Plan Policy
\item End User Encryption Key Protection Policy
\item Acquisition Assessment Policy
\item Bluetooth Baseline Requirements Policy
\item Remote Access Policy
\item Remote Access Tools Policy
\item Router and Switch Security Policy
\item Wireless Communication Policy
\item Wireless Communication Standard
\item Database Credentials Policy
\item Technology Equipment Disposal Policy
\item Information Logging Standard
\item Lab Security Policy
\item Server Security Policy
\item Software Installation Policy
\item Workstation Security (For HIPAA) Policy
\item Web Application Security Policy
\end{list2}
\end{quote}
Source: \url{https://www.sans.org/information-security-policy/}

Example, how do you handle BYOD Bring your own devices, educational institutions you expect students to bring them, in a secure enterprise only company devices may be allowed.

{\bf Solution:}\\
When you have seen at least two different policies you are done.

{\bf Discussion:}\\
How do you both write AND create awareness about a policy?





\chapter{\faExclamationTriangle\ SSL/TLS scanners 15min}
\label{ex:sslscan}

\hlkimage{10cm}{ncsc-tls-version-detail.png}

{\bf Objective:}\\
Try the Online Qualys SSLLabs scanner \link{https://www.ssllabs.com/}
Try the command line tool sslscan checking servers - can check both HTTPS and non-HTTPS protocols!

{\bf Purpose:}\\
Learn how to efficiently check TLS settings on remote services.

{\bf Suggested method:}\\
Run the tool against a couple of sites of your choice.

\begin{alltt}\small
root@kali:~# sslscan www.kramse.org
Version: 1.10.5-static
OpenSSL 1.0.2e-dev xx XXX xxxx

Testing SSL server web.kramse.dk on port 443
...
  SSL Certificate:
Signature Algorithm: sha256WithRSAEncryption
RSA Key Strength:    2048

Subject:  *.kramse.dk
Altnames: DNS:*.kramse.dk, DNS:kramse.dk
Issuer:   AlphaSSL CA - SHA256 - G2
\end{alltt}

Also run it against SMTPTLS if possible. Choose a mail server,\\
 \verb+mail.kramse.org+ can work like this:\\
\verb+sslscan   --starttls-smtp mail.kramse.org:25+

{\bf Hints:}\\
Originally sslscan is from \link{http://www.titania.co.uk} but use the version on Kali, install with apt if not installed.

{\bf Solution:}\\
When you can run and understand what the tool does, you are done.

{\bf Discussion:}\\
SSLscan can check your own sites, while Qualys SSLLabs only can test from hostname




\chapter{\faInfoCircle\ SSH scanners 15min}
\label{ex:nmap-ssh-scanner}

\hlkimage{10cm}{openssh-banner.png}

{\bf Objective:}\\
Try ssh scanners, similar to sslscan and Nmap sshscan

{\bf Purpose:}\\
We often need to find older systems with old settings.

{\bf Suggested method:}\\
Use Nmap with built-in scripts for getting the authentication settings from SSH servers

{\bf Hints:}\\
Nmap includes lots of scripts, look into the directory on Kali:

\begin{alltt}\footnotesize
$ ls /usr/share/nmap/scripts/*ssh*
/usr/share/nmap/scripts/ssh2-enum-algos.nse   /usr/share/nmap/scripts/ssh-publickey-acceptance.nse
/usr/share/nmap/scripts/ssh-auth-methods.nse  /usr/share/nmap/scripts/ssh-run.nse
/usr/share/nmap/scripts/ssh-brute.nse	      /usr/share/nmap/scripts/sshv1.nse
/usr/share/nmap/scripts/ssh-hostkey.nse

$ sudo nmap -A -p 22 --script "ssh2-enum-algos,ssh-auth-methods" 10.0.45.2
Starting Nmap 7.80 ( https://nmap.org ) at 2020-02-20 08:46 CET
Nmap scan report for 10.0.42.6
Host is up (0.0038s latency).

PORT   STATE SERVICE VERSION
22/tcp open  ssh     Cisco/3com IPSSHd 6.6.0 (protocol 2.0)
| ssh-auth-methods:
|   Supported authentication methods:
|     publickey{\color{red}
|_    password}
| ssh2-enum-algos:
|   kex_algorithms: (1)
|       diffie-hellman-group1-sha1
|   server_host_key_algorithms: (1)
|       ssh-dss
|   encryption_algorithms: (6)
|       aes128-cbc
|       aes192-cbc
|       aes256-cbc
|       blowfish-cbc{\color{red}
|       cast128-cbc
|       3des-cbc}
|   mac_algorithms: (4)
|       hmac-sha1
|       hmac-sha1-96
|       hmac-md5
|       hmac-md5-96
|   compression_algorithms: (1)
|_      none
\end{alltt}

{\bf Solution:}\\
When you have tried running against one or two SSH servers, you are done.

{\bf Discussion:}\\
I recommend disabling password login on systems connected to the internet.

Having only public key authentication reduces or even removes the possibility for brute force attacks succeeding.

I also move the service to a random high port, which then requires an attacker must perform port scan to find it - more work.

Thus a better and more modern OpenSSH would look like this:
\begin{alltt}\footnotesize
PORT      STATE SERVICE VERSION
4xxxx/tcp open  ssh     OpenSSH 7.9 (protocol 2.0)
| ssh-auth-methods:
|   Supported authentication methods:
|     publickey
| ssh2-enum-algos:
|   kex_algorithms: (4)
|       curve25519-sha256@libssh.org
|       diffie-hellman-group16-sha512
|       diffie-hellman-group18-sha512
|       diffie-hellman-group14-sha256
|   server_host_key_algorithms: (4)
|       rsa-sha2-512
|       rsa-sha2-256
|       ssh-rsa
|       ssh-ed25519
|   encryption_algorithms: (6)
|       chacha20-poly1305@openssh.com
|       aes128-ctr
|       aes192-ctr
|       aes256-ctr
|       aes128-gcm@openssh.com
|       aes256-gcm@openssh.com
|   mac_algorithms: (3)
|       umac-128-etm@openssh.com
|       hmac-sha2-256-etm@openssh.com
|       hmac-sha2-512-etm@openssh.com
|   compression_algorithms: (2)
|       none
|_      zlib@openssh.com
\end{alltt}


\chapter{\faExclamationTriangle\ Perform privilege escalation using files 30min}
\label{ex:priv-esc-cron}

\hlkimage{10cm}{df20030604.jpg}

{\bf Objective:}\\
Perform a simple privilege escalation attack

{\bf Purpose:}\\
Try and test a back door script. We will create this ourselves, but could have been left by an attacker.

{\bf Suggested method:}\\

\begin{enumerate}
\item Create a shell copy with SUID bit set as privileged user
\item Run the command as non-privileged user to see if it works
%\item Create root cronjob without path
%\item Insert a malicious script as one of the commands from the root cron job
\end{enumerate}

{\bf Hints:}\\
In this exercise first try out the malicious commands for creating a back door shell program. Login in as root, then:

\begin{alltt}
root@debian:~# rm /tmp/.xxsh
root@debian:~# apt install zsh
...
root@debian:~# cp /bin/zsh /tmp/.xxsh
root@debian:~# chmod +sw /tmp/.xxsh
\end{alltt}

Then test using a normal user, another window:
\begin{alltt}
hlk@debian:~$ /tmp/.xxsh
# id
uid=1000(hlk) gid=1000(hlk) {\bf euid=0(root) egid=0(root)} groups=0(root),24(cdrom),25(floppy),
29(audio),30(dip),44(video),46(plugdev),108(netdev),112(lpadmin),117(scanner),1000(hlk)
 context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
#
\end{alltt}

The effective user id should be 0 which is root. It might not work as intended, due to enhanced security in the shell programs! Namely it wont work with Bourne Again Shell (bash) but maybe with dash. If dash is not installed, try installing it.

{\bf Shell programs are getting better, implement more security. zsh might not work, but try to find another shell program.}

When this manual process work. Then automate it, make it into a small script. Imagine if the root user was running automated scripts, and you could add yours to a directory used in the PATH for these automated ones.

This happens in a lot of devices and hosts today.

The main takeaway is that root scripts should ALWAYS have a PATH defined, and ALL directories used by root script should only be writable by root!

{\bf Solution:}\\
When you have created the script for doing the shell copy you are done.

Further advanced steps would be to add this into some PATH writable by you, and letting a cron job escalate.

Then do a cron job that uses this command - a cron job running every 5 minutes using the \verb+ls+ command and introduce your malicious script by putting it before the real command in the PATH.



{\bf Discussion:}\\
Why is the file named with a dot as the first character?

Does the /tmp folder need to be a place to run scripts? No, but many applications unfortunately require exactly this.

What is defense in depth? Does it apply here?

Finish off the exercise by running, and looking at the output from:\\
\verb+find / -perm -4000 -o -perm -6000+




\chapter{\faInfoCircle\ Small programs with data types 15min}
\label{ex:c-types}

{\bf Objective:}\\
Try out small programs similar to:
\inputminted{c}{programs/int1.c}

\begin{alltt} \footnotesize
user@Projects:programs$ gcc -o int1 int1.c && ./int1
First debug int is 32767
Second debug int is now -32768
\end{alltt}

{\bf Purpose:}\\
See actual overflows when going above the maximum for the selected types.


{\bf Suggested method:}\\
Compile program as is. Run it. See the problem. Then try changing the int type, try without short, and with signed and unsigned. Note differences

{\bf Hints:}\\
Use a calculator to find the maximum, like $2^{16}$, $2^{32}$ etc.

{\bf Solution:}\\
When you have tried adding one to a value and seeing it going negative, you are done.

{\bf Discussion:}\\
Computers are not always correct when doing calculations. Above was shown with integers, and it is even worse for floating point.

\begin{quote}\footnotesize
The IEEE Standard for Floating-Point Arithmetic (IEEE 754) is a technical standard for floating-point arithmetic established in 1985 by the Institute of Electrical and Electronics Engineers (IEEE). The standard addressed many problems found in the diverse floating-point implementations that made them difficult to use reliably and portably. Many hardware floating-point units use the IEEE 754 standard.
\end{quote}

Source: \url{https://en.wikipedia.org/wiki/IEEE_754}


\chapter{\faExclamationTriangle\ Real Vulnerabilities up to 30min}
\label{ex:real-vulns-exim}

\hlkimage{5cm}{log4j-logo.png}

{\bf Objective:}\\
Look at real vulnerabilities. Choose a few real vulnerabilities, prioritize them.

{\bf Purpose:}\\
See that the error types described in the books - are still causing problems.

{\bf Suggested method:}\\
We will use the 2019 Exim errors as starting examples. Download the descriptions from:
\begin{list2}
\item Exim RCE CVE-2019-10149 June\\ \url{https://www.qualys.com/2019/06/05/cve-2019-10149/return-wizard-rce-exim.txt}

\item Exim RCE CVE-2019-15846 September\\
\url{https://exim.org/static/doc/security/CVE-2019-15846.txt}
\end{list2}

When done with these think about your own dependencies. What software do you depend on? How many vulnerabilities and CVEs are for that? Each year has huge new vulnerabilities, like the 2020 and 2021 shown above.

\begin{list2}
\item CVE-2020 Netlogon Elevation of Privilege \\
\link{https://msrc.microsoft.com/update-guide/vulnerability/CVE-2020-1472}
\item Log4J RCE (CVE-2021-44228) - and follow up like CVE-2021-45046, also look at scanners like:\\
\link{https://github.com/fullhunt/log4j-scan}
\end{list2}

What is CVSS -- Common Vulnerability Scoring System?\\
\url{https://nvd.nist.gov/vuln-metrics/cvss}

I depend on the OpenBSD operating system, and it has flaws too:\\
\url{https://www.openbsd.org/errata65.html}

You may depend on OpenSSH from the OpenBSD project, which has had a few problems too:\\
\url{https://www.openssh.com/security.html}

{\bf Hints:}\\
Remote Code Execution can be caused by various things, but most often some kind of input validation failure.

{\bf Solution:}\\
When you have identified the specific error type, is it buffer overflows? Then you are done.

{\bf Discussion:}\\
How do you feel about running internet services. Lets discuss how we can handle running insecure code.
What other methods can we use to restrict problems caused by similar vulnerabilities.
A new product will often use a generic small computer and framework with security problems.



\chapter{\faExclamationTriangle\ Research Virtual Machine Escapes 20min}
\label{ex:vm-escape}


{\bf Objective:}\\
Research how exploits can escape from Guest Virtual Machine to Host operating system. Multiple examples exist for both client virtualisation and datacenter virtualisation.

{\bf Purpose:}\\
Research VM escapes - understand that isolation and separation does not always work. Think about how to design systems with this in mind. Perhaps virtualisation should be built using two clusters, one for external services and one for internal?

{\bf Suggested method:}\\
Find list of CVE or do internet search. Perform searches using the virtualisation technology used in your networks. Note: even though Virtual box is used as example below other technologies like Microsoft HyperV, VMware, Xen etc. have similar problems!


examples:

\begin{itemize}
\item \link{https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=virtualbox} list multiple vulnerabilities.
\item \url{https://github.com/MorteNoir1/virtualbox_e1000_0day} \emph{VirtualBox E1000 Guest-to-Host Escape} The E1000 has a vulnerability allowing an attacker with root/administrator privileges in a guest to escape to a host ring3. Then the attacker can use existing techniques to escalate privileges to ring 0 via /dev/vboxdrv.
\item \url{https://en.wikipedia.org/wiki/Virtual_machine_escape}
\end{itemize}

{\bf Hints:}\\
Providing virtualisation is today done using hardware features in the CPU of the system. Along with the hardware features are drivers and features provided by the virtualisation system, which has errors.

Having drivers and kernel modules with errors can sometimes result in flaws exploitable by guest virtual machines.

{\bf Solution:}\\
There is often no solution other than to patch systems, when new vulnerabilities are found - update your virtualisation NOW if you are missing updates.

Never open virtual machines from untrusted sources on your laptop with confidential data. Don't trust that the security provided is enough for researching live malware on virtual systems.

{\bf Discussion:}\\
Is it possible to create multiple virtualisation cluster? - yes, some organisations already have multiple clusters for various reasons. Some might have development, staging and production as different clusters.

Also be aware that a lot of malware has checks trying to find out if it is running in a virtual machine, or isolated in a lab.

Update 2024: it seems VMware just released some patches for important updates to their ESXi products. See if you can locate an article either on the internet or at VMware.com describing these problems.




\chapter{\faInfoCircle\ Try running a Docker container 20min}
\label{ex:docker-run}


{\bf Objective:}\\
Research how Docker containers work.

{\bf Purpose:}\\
Docker containers are used all around the world, often together with private cloud systems.
They run in the host OS kernel, and thus requires fewer resources, and provides less isolation.

\begin{quote}\small
The underlying technology\\
Docker is written in the Go programming language and takes advantage of several features of the Linux kernel to deliver its functionality. Docker uses a technology called namespaces to provide the isolated workspace called the container. When you run a container, Docker creates a set of namespaces for that container.

These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace.
\end{quote}
Source: \url{https://docs.docker.com/get-started/overview/}

{\bf Suggested method:}\\
Find the main web page of Docker, \url{https://www.docker.com}

Look at the architecture of Docker, they currently have an article:\\
\url{https://www.docker.com/resources/what-container}

What is a Container?\\
A standardized unit of software

Browse the architecture for a bit, and then run docker on your Debian.

The instruction are on the page:\\
\url{https://docs.docker.com/engine/install/debian/}

{\bf Note: I have added a directory in my kramse-labs with playbooks for installing on Debian -- use them!}

\begin{alltt}\small
user@Projects:~$ cd projects/github/kramse-labs/
user@Projects:kramse-labs$ ls
core-net-lab/	 lab-network/	work-station/  README.md
docker-install/  suricatazeek/	LICENSE
user@Projects:kramse-labs$ cd docker-install/
user@Projects:docker-install$ pwd
/home/user/projects/github/kramse-labs/docker-install
user@Projects:docker-install$ ls
1-dependencies.yml  README.md
user@Projects:docker-install$ ansible-playbook 1-dependencies.yml
... about 10 minutes at most
\end{alltt}

{\bf Hints:}\\
I recommend using the repositories, as future updates will become available there. This make future apt update/upgrade more simple.

{\bf Solution:}\\
When you understand the basic architecture of Docker containers, you are done.

or

When you can run a small docker container, you are done.


\begin{minted}[fontsize=\footnotesize]{shell}
docker run hello-world
\end{minted}


{\bf Discussion:}\\
Many software packages can be used via Docker containers. This allows the programmer to prepare a small image, and the user to run this directly.

Are there any security issues, many, so be careful.

See for example: \\
\url{https://docs.docker.com/engine/security/}



\chapter{\faExclamationTriangle\ Research Cisco ACI security assessment 20min}
\label{ex:cisco-aci-ernw}


{\bf Objective:}\\
Research how the product from Cisco named Application Centric Infrastructure was assessed by german security company ERNW.

{\bf Purpose:}\\
Research ACI vulnerabilities -- understand what when isolation and separation is not implemented. Think about how to design systems with this in mind. Perhaps security infrastructure should be built using modern methods. Say not using the root user for EVERYTHING, like we found out in the 1990s.

{\bf Suggested method:}\\
Download the white paper 68 from ERNW:\\
\url{https://ernw.de/en/whitepapers/issue-68.html}

\begin{itemize}
\item Browse table of contents
\item Look into one or more of the vulns, read about it
\item Perhaps look it up in the CVE databases, and find CVSS
\item Search for Cisco ACI and see if further vulns have been found over the years since 2019 (there have)
\end{itemize}

{\bf Hints:}\\
There are these vulnerabilities to select from:
\begin{list2}
\item Remote Code Execution on Leaf Switches over IPv6 via Local SSH Server (CVE-2019-1836, CVE2019-1803, and CVE-2019-1804)
\item Cisco Nexus 9000 Series Fabric Switches ACI Mode Fabric Infrastructure VLAN Unauthorized
  Access Vulnerability (CVE-2019-1890)
\item Cisco Nexus 9000 Series Fabric Switches Application Centric Infrastructure Mode Link Layer
  Discovery Protocol Buffer Overflow Vulnerability (CVE-2019-1901)\\
  This specific daemon is running as root
\item Cisco Application Policy Infrastructure Controller REST API Privilege Escalation Vulnerability (CVE-2019-1889)
\end{list2}


{\bf Solution:}\\
When you have read about one of the vulnerabilities found and understood it, you are done.

{\bf Discussion:}\\
Shouldn't a product by Cisco for security purposes using Linus use the most basic of controls?

I found it horrible and inside the system there were many examples of insecure scripting, bad habits, no security designed or implemented -- rather the opposite.

Running everything as root make every little mistake become a serious issue.

\chapter{\faExclamationTriangle\ Lynis Auditing, System hardening, and Compliance testing 20min}
\label{ex:lynis-first}

\hlkimage{10cm}{lynis.png}

{\bf Objective:}\\
Try out the Lynis tool for scanning your local Unix server.

{\bf Purpose:}\\
Lynis is a quick tool to run, and gives concrete advise for things to change.

{\bf Suggested method:}\\
Install using APT on your Debian and run the tool



{\bf Hints:}\\
Use the web site for the tool Lynis \url{https://cisofy.com/lynis/} and audit your system

{\bf Solution:}\\
When you have run the tool you are done. Better if you have browsed some of the output

{\bf Discussion:}\\




\chapter{\faExclamationTriangle\ Centralized syslog 15min}
\label{ex:centralized-syslog-practical}

{\bf Objective:} \\
See how server syslog is configured on regular Unix/Linux.

Centralized syslogging and example system can demonstrate how easy it is to get started

{\bf Purpose:}\\
The main idea of this exercise is to understand how easy network connected systems can send log data.

This should be the common case, sending logs off system - to avoid an attacker being able to hide tracks and logs from exploits performing intrusion and escalation.

{\bf Suggested method:}\\
Log into your local Linux systems or network devices, see how syslog is configured.

{\bf Hints:}\\
Look in the config file, may be in /etc/syslog  or /etc/syslog-ng/syslog-ng.conf

Sample output from old-skool syslogd
\begin{alltt}
\small
*.err;kern.debug;auth.notice;authpriv.none;mail.crit    /dev/console
*.notice;auth,authpriv,cron,ftp,kern,lpr,mail,user.none /var/log/messages
kern.debug;user.info;syslog.info                        /var/log/messages
auth.info                                               /var/log/authlog
authpriv.debug                                          /var/log/secure
...
# Uncomment to log to a central host named "loghost".
#*.notice;auth,authpriv,cron,ftp,kern,lpr,mail,user.none        @loghost
#kern.debug,user.info,syslog.info                               @loghost
#auth.info,authpriv.debug,daemon.info                           @loghost
\end{alltt}

{\bf Solution:}\\
When you understand how to configure syslog from a couple of devices and has looked up which protocol and port it uses. (default is 514/udp)

{\bf Discussion:}\\
There are syslog senders for Windows too. Other systems define their own format for sending, example Beats - lightweight data shippers \link{https://www.elastic.co/products/beats }

I recommend using the elastic stack, previously the ELK stack, \link{https://www.elastic.co/products/}. The products can be used without license and can give a lot of experience with this kind of product. This will enable you to better describe your logging needs for evaluating other products.

This is done using Logstash as the server - can also receive SNMP traps!

Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite “stash.” - often Elasticsearch
\link{https://www.elastic.co/products/logstash}

Other very popular systems are:

\begin{itemize}
\item Splunk \link{https://www.splunk.com}
\item Graylog \link{https://www.graylog.org/}
\item InfluxDB \link{https://www.influxdata.com/}
\item Grafana The open platform for analytics and monitoring \link{https://grafana.com/} also includes Grafana Loki now \link{https://grafana.com/oss/loki/}
\item Prometheus Monitoring system \& time series database \link{https://prometheus.io/}
\end{itemize}

Remember doing logging og performance metrics can also become a security charateristics. Availability is a critical metric for most commercial systems.


\chapter{\faInfoCircle\ Getting started with the Elastic Stack 15min}
\label{gettingstartedelastic}

\hlkimage{10cm}{illustrated-screenshot-hero-kibana.png}

Screenshot from \url{https://www.elastic.co/kibana}

{\bf Objective:}\\
Get ready to start using Elasticsearch, read - but dont install.

{\bf Purpose:}\\
We need some tools to demonstrate integration. Elasticsearch is a search engine and ocument store used in a lot of different systems, allowing cross application integration.


{\bf Suggested method:}\\
Visit the web page for \emph{Getting started with the Elastic Stack} :\\
{\footnotesize\url{https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-elastic-stack.html}}

Read about the tools, and the steps needed for manual installation.

{\bf You dont need to install the tools currently}, I recommend using Debian and Ansible for bringing up Elasticsearch.
You are of course welcome to install, or try the Docker method.


{\bf Hints:}\\
Elasticsearch is the name of the search engine and document store. Today Elastic Stack contains lots of different parts.

We will focus on these parts:
\begin{itemize}
\item Elasticsearch - the core engine
\item Logstash - a tool for parsing logs and other data.\\
\url{https://www.elastic.co/logstash}
\begin{quote}
"Logstash dynamically ingests, transforms, and ships your data regardless of format or complexity. Derive structure from unstructured data with grok, decipher geo coordinates from IP addresses, anonymize or exclude sensitive fields, and ease overall processing."
\end{quote}
\item Kibana - a web application for accessing and working with data in Elasticsearch\\
\url{https://www.elastic.co/kibana}
\end{itemize}

{\bf Solution:}\\
When you have browsed the page you are done.

{\bf Discussion:}\\
You can read more about Elasticsearch at the wikipedia page:\\
\url{https://en.wikipedia.org/wiki/Elasticsearch}


\chapter{\faInfoCircle\ Run Elasticsearch in Containers 30min}
\label{ex:selks}

{\bf Objective:}\\
Run an Elasticsearch stack with Suricata IDS in containers

{\bf Purpose:}\\
See how easy it is to test various solutions, even if they are complicated

{\bf Suggested method:}\\
Use the kickstart-2-selks.pdf document in Fronter.

The steps are also outlined in their repository \url{https://github.com/StamusNetworks/SELKS.git}

I would like for you to install Docker and try out SELKS \url{https://www.stamus-networks.com/selks}

If you want to use the same as me with Debian VM, which installs in less than 30minutes:
\begin{list1}
\item[\faSquareO] Install a basic Debian 12 Bookworm with Sudo configured
\item[\faSquareO] Install git and Ansible, see our exercise:\\
\verb+sudo apt install git ansible+
\item[\faSquareO] Clone the Github repo: \link{https://github.com/kramse/kramse-labs}\\
\verb+git clone https://github.com/kramse/kramse-labs+
\item[\faSquareO] Go into this repository and install Docker, there is a small README.md too:\\
\verb+cd kramse-labs/docker-install+ and then \verb+ansible-playbook 1-dependencies.yml+
\item[\faSquareO] Enable Docker: \verb+systemctl enable docker+ and reboot the VM
\item[\faSquareO] Check docker, \verb+docker run hello-world+
\item[\faSquareO] Clone the SELKS repository:\\
\verb+git clone https://github.com/StamusNetworks/SELKS.git+
\item[\faSquareO] Go into this and run docker-compose as described in the instructions:\\
\url{https://github.com/StamusNetworks/SELKS/wiki/Docker}\\
{\bf  make sure to select the right network interface, so Suricata can sniff packets}
{\bf I did NOT install Portainer}
\item[\faSquareO] Use a browser to access the platform on \url{https://127.0.0.1} -- and enjoy!
\end{list1}

This will provide a basic Elasticsearch version 7, with Kibana and Suricata


{\bf Hints:}\\
Make sure your Debian has enough memory, 8Gb will run, less will be tough, more will be better.

{\bf Solution:}\\
When you have seen the system on the instructors PC your are done.

{\bf Discussion:}\\
There are lots of projects that allow you to test solution from containers. This is often much easier and faster then following the instructions for installing the project.
On the other hand, you may want to follow install instructions if it for a production setup.

\chapter{\faInfoCircle\ Create Kibana Dashboard 15min}
\label{ex:kibana-dashboard}

\hlkimage{12cm}{kibanascreenshothomepagebannerbigger.jpg}

{\bf Objective:}\\
See Kibana and understand how it is configured.

{\bf Purpose:}\\
Kibana is a very popular system for creating dashboards from data in elasticsearch.

Learning how to create and import dashboards is a good exercise.

{\bf Suggested method:}\\
Instructor will provide a method for running Elasticsearch and Kibana for this exercise. See the previous exercise \smiley

Note: usually Kibana should be available on port 5601 on localhost (127.0.0.1) only! It is recommended to keep this configuration and then add a web server like Nginx or Apache in front. This will further allow authentication and other features.

Using Firefox visit Kibana on the link provided by the instructor.

If this is the first time you need to
 select \verb+logstash-*+ as a default index. Note: Kibana is an advanced and powerful tool in itself.


{\bf Hints:}\\
Logstash and Elastic stack are a great way to get started with dashboarding.

However, running a big installation is harder than it looks. Make sure to have multiple servers and good monitoring.

{\bf Solution:}
When you have browsed Kibana, seen how you can add graphs and combine them into dashboards - using the GUI you are done. Previously creating dashboards was harder and often required programming knowledge.

{\bf Discussion:}\\
Making dashboard are an art form. We will NOT start creating beautiful dashboards.

If you want, there is a SELKS LiveCD dedicated to suricata which also includes more tools for administration of rules and getting alerts:\\
\link{https://www.stamus-networks.com/open-source/}

Dashboards can be exported as JSON into files, and can be loaded using shell commands, example the ones from:
\link{https://github.com/StamusNetworks/KTS7}

The commands are similar to
\begin{alltt}
git clone https://github.com/StamusNetworks/KTS7.git
cd KTS7
bash load.sh
\end{alltt}

Note: KTS version needs to match Elasticsearch version! So for ES version 7, use KTS7







\end{document}

\chapter{}
\label{ex:}

{\bf Objective:}\\


{\bf Purpose:}\\


{\bf Suggested method:}\\


{\bf Hints:}\\


{\bf Solution:}\\


{\bf Discussion:}\\
