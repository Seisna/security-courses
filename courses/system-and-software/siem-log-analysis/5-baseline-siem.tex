\documentclass[Screen16to9,17pt]{foils}
\usepackage{zencurity-slides}
\externaldocument{siem-log-analysis-exercises}
\selectlanguage{english}

\begin{document}

\mytitlepage
{5. Baseline Your Data}
{KEA Kompetence SIEM and Log Analysis}


\slide{Goals for today}

\hlkimage{6cm}{thomas-galler-hZ3uF1-z2Qc-unsplash.jpg}

Todays goals:
\begin{list2}
\item How would you design a minimal production setup
\item Selecting technology -- some recommendations
\item Alerting and reporting -- what is available now in your systems
\end{list2}

  Photo by Thomas Galler on unsplash

\slide{Plan for today}

\begin{list1}
\item Subjects
\begin{list2}
\item Real systems, how to design
\item Technology options
\item A little Veris, and regular/yearly state-of-reports
\end{list2}
\item Exercise theme: Moving into a real deployment
\begin{list2}
\item Mostly discussion about options for deploying SIEM tools and technologies
\item Alerting and reporting
\end{list2}
\end{list1}

Follow up from last, Dashboard example designed for Kibana -- I don't use it myself YMMV\\
\link{https://github.com/devdjdjdj/kibana-presenter}

\slide{Reading Summary}

\begin{list1}
\item DDS 7. Learning from Security Breaches VERIS
\item DDS 12. Moving Toward Data-Driven Security
\item IDIR 1. Introduction
\item IDIR 2. Basics of Intelligence
\end{list1}


\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}

\end{quote}

Source: DDS 7. Learning from Security Breaches VERIS
\begin{list2}
\item We all see the same attacks, make it easier to communicate between applications and organizations
\item Learn from others
\item Another example MITRE ATT\&CK® \link{https://attack.mitre.org/}
\end{list2}

We will now browse the chapter, and discuss your experiences

\slide{Reading Summary, continued}

\hlkimage{8cm}{jay-data-science-workflow.png}

\begin{quote}
\begin{list2}
\item Find and Collect Relevant Data
\item Learn through Iteration
\item Find Statistics
\end{list2}

\end{quote}
Source: DDS 12. Moving Toward Data-Driven Security


\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}{\bf
Building a Real-Life Security Data Science Team}\\

... a clear goal: Given an IP address (or IP/Port combination), {\bf search across all our perimeter devices in less than five minutes.}

Three core principles focused the team.
\begin{list2}
\item First, explore the open source versions of tools before engaging vendors. If you don’t
know how the sausage is being made, you really have no idea what’s being done, and
this is vital when working with real data.
\item Second, follow the mantra of “no single tool; no single database; and, no single approach
to solving a problem.” Do not put blinders on because you are either comfortable with
certain technologies or have an affinity for a certain tool.
\item Third, failure is expected, but you must learn from each journey down the wrong path.
Continuous adaptation and adjustment is the name of the game.
\end{list2}
\end{quote}

Source: DDS 12. Moving Toward Data-Driven Security





\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}
When you begin implementing intelligence-driven incident response, it is important to have a solid understanding of both intelligence and incident-response processes. Part 1 provides an introduction to cyber-threat intelligence, the intelligence process, the incident-response process, and how they all work together.
\end{quote}
Source: IDIR 1. Introduction

\begin{list2}
\item Obviously a book about incident response, but a modern one
\end{list2}

\slide{Reading Summary, continued}

%\hlkimage{}{}

\begin{quote}
There was a time when many people considered indicators of compromise, or IOCs, to be synonymous with threat intelligence. IOCs, which we will reference a lot and cover in depth later in the book, are things to look for on a system or in network logs that may indicate that a compromise has taken place. This includes IP addresses and domains associated with command-and-control servers or malware downloads, hashes of malicious files, and other network- or host-based artifacts that may indicate an intrusion. As we will discuss throughout this book, however, there is far more to threat intelligence than IOCs, although IOCs still remain one of the most common types of technical intelligence around intrusions.
\end{quote}
Source:  IDIR 2. Basics of Intelligence

\begin{list2}
\item List sources of intelligence, HUMINT, OSINT, SIGINT etc.
\item Introduces the OODA loop, “observe, orient, decide, act.” and the Intelligence Cycle
\item OODA loop also used in the SOC book
\end{list2}

\slide{}

%\hlkimage{}{}

\begin{quote}{\bf
Data is a piece of information, a fact, or a statistic.} Data is something that describes
something that is. In our previous example about the weather report, the temperature
is a piece data. It is a fact, something that has been measured using a {\bf proven and
repeatable process}. Knowing the temperature is important, but in order to be useful
for decision making, it must be analyzed in the context of what else is going on that
day. {\bf In information security, an IP address or domain are data.} Without any addi‐
tional analysis to provide context, they are simply facts. When various {\bf data points are
gathered and analyzed} to provide {\bf insight} around a particular requirement, it {\bf becomes
intelligence}.
\end{quote}
Source:  IDIR 2. Basics of Intelligence

\begin{list2}
\item Without data we cannot do much
\item If you have an incident, and there will be incidents, you need it!
\item Better gather some basic data now, even if you don't use it currently
\end{list2}

\slide{}

%\hlkimage{}{}

\begin{quote}{\bf
Intelligence is derived from a process of collecting, processing, and analyzing data.}
Once it has been analyzed, it {\bf must be disseminated} in order to be useful. Intelligence
that does not get to the right audience is wasted intelligence. Wilhelm Agrell, a Swedish writer and historian who studied peace and conflict, once famously said, “Intelligence analysis combines the dynamics of journalism with the problem solving of science.”
\end{quote}
Source:  IDIR 2. Basics of Intelligence

\begin{list2}
\item Sharing data helps us and others
\item We can use many sources of data to enable quicker response
\end{list2}


\slide{Indicators of Compromise }

\begin{quote}
There was a time when many people considered indicators of compromise, or IOCs,
to be synonymous with threat intelligence. IOCs, which we will reference a lot and
cover in depth later in the book, are {\bf things to look for} on a system or in {\bf network logs} that may {\bf indicate that a compromise has taken place}. This includes IP addresses and domains associated with command-and-control servers or malware downloads, hashes of malicious files, and other network- or host-based artifacts that may indicate an intrusion.
\end{quote}
Source: \emph{Intelligence-Driven Incident Response} (IDIR)\\
 Scott Roberts. Rebekah Brown



\slide{Indicators of Compromise and Signatures}

\begin{quote}
An IOC is any piece of information that can be used to objectively describe a
network intrusion, expressed in a platform-independent manner. This could include a simple indicator such as the IP address of a command and control (C2) server or a complex set of behaviors that indicate that a mail server is being used as a malicious SMTP relay.

When an IOC is taken and used in a platform-specific language or format, such as a Snort Rule or a Zeek-formatted file, it becomes part of a signature. A signature can contain one or more IOCs.
\end{quote}

Source: Applied Network Security Monitoring Collection, Detection, and Analysis, 2014 Chris Sanders


\slide{OODA Loop by John Boyd}

\hlkimage{20cm}{OODA.Boyd.png}
Source: Patrick Edwin Moran - Wikipedia \link{https://en.wikipedia.org/wiki/OODA_loop}



\slide{Intelligence Cycle or Intelligence Process}

\hlkimage{9cm}{The_Intelligence_Process_JP_2-0.png}
Source: \link{https://en.wikipedia.org/wiki/Intelligence_cycle}

\begin{list2}
\item I decided to take the more original Intelligence Process picture, which has a bit more details
\end{list2}

\slide{Processing}

Let's look at some processing

\begin{list2}
\item Processing includes normalizing collected data into uniform formats for analysis
\item Indexing -- Large volumes of data need to be made searchable
\item Translation -- for our course we might get multiple input formats but need JSON or XML
\item Enrichment -- Providing additional metadata for a piece of information is important. For example, domain addresses need to be resolved to IP addresses, and {\bf WHOIS registration data fetched}
\item Filtering --
Not all data provides equal value, and analysts can be overwhelmed when presen‐
ted with endless streams of irrelevant data
\item Prioritization --
The data that has been collected may need to be ranked so that analysts can allo‐
cate resources to the most important items\\
Note: this relates to a \emph{baseline}, what errors are normal in your environment
\item Visualization -- Data visualization has advanced significantly and the human eye and brain can often see patterns
\end{list2}


\slide{Metadata -- enrichment}

\hlkimage{10cm}{crafting-security-playbook-metadata.png}

Source: picture from Crafting the InfoSec Playbook, CIP

Metadata + Context



\slide{Drill down process}

%\hlkimage{}{}

\begin{quote}

\end{quote}

We have seen Kibana multiple times, but how do you use it? I recommend the following iterative process
\begin{enumerate}
\item Get an overview
\item Research top talkers,
\item When identified and handled, remove with filter \verb+not host 10.1.2.3+
\item Look at the next ones
\end{enumerate}

Look into details, lookup hostnames -- hopefully your tool allows some help




\slide{How to get started}

\begin{list1}
\item How to get started searching for security events?
\item Collect basic data from your devices and networks
\begin{list2}
\item Netflow data from routers
\item Session data from firewalls
\item Logging from applications: email, web, proxy systems
\end{list2}
\item {\bf Centralize!}
\item Process data
\begin{list2}
\item Top 10: interesting due to high frequency, occurs often, brute-force attacks
\item {\it ignore}
\item Bottom 10: least-frequent messages are interesting
\end{list2}
\end{list1}





\slide{Logstash pipeline }

\begin{quote}
  Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite “stash.” (Ours is Elasticsearch, naturally.)\\
  \link{https://www.elastic.co/products/logstash}
\end{quote}

\begin{verbatim}
input { stdin { } }
output {
  elasticsearch { host => localhost }
  stdout { codec => rubydebug }
}
\end{verbatim}



\begin{list2}
\item Logstash receives via {\bf input}
\item Processes with {\bf filters} - grok
\item Forward events with {\bf output}
\end{list2}


\slide{Logstash as SNMPtrap and syslog server}

{\footnotesize
\begin{verbatim}
input {
  snmptrap {
    host => "0.0.0.0"
    type => "snmptrap"
    port => 1062
    community => "xxxxx"   }
  tcp {
    port => 5000
    type => syslog  }
  udp {
    port => 5000
    type => syslog  }
}
\end{verbatim}
}

\begin{list2}
\item We run logstash on port 5000 - but use IPtables port forwarding
\item Have you even configured SNMP traps?
\item Maybe you have a device sending SNMP traps right now ...
\end{list2}

\slide{IPtables forwarding}

{\footnotesize
\begin{verbatim}
*nat
:PREROUTING ACCEPT [0:0]
# redirect all incoming requests on port 514 to port 5000
-A PREROUTING -p tcp --dport 514 -j REDIRECT --to-port 5000
-A PREROUTING -p udp --dport 514 -j REDIRE}}CT --to-port 5000
-A PREROUTING -p udp --dport 162 -j REDIRECT --to-port 1062
COMMIT
\end{verbatim}
}

\centerline{Inserted near beginning of /etc/ufw/before.rules on Ubuntu}

Remember defense in depth, dont run a privileged Java VM process as root \smiley

\slide{Grok expresssions}

{\footnotesize
\begin{verbatim}
  filter {
    if [type] == "syslog" {
      grok {
        match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp}
        %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}
        (?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
        add_field => [ "received_at", "%{@timestamp}" ]
        add_field => [ "received_from", "%{host}" ]
      }
      syslog_pri { }
      date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
    }
  }
\end{verbatim}
}

\begin{list2}
\item Logstash filter expressions grok can normalize and split data into fields
\end{list2}

Source:
Config snippet from\\
{\small\link{http://logstash.net/docs/1.4.1/tutorials/getting-started-with-logstash}}



\slide{Lets design a SIEM Infrastructure Proof of Concept}

\hlkimage{16cm}{demo-siem-setup.pdf}


\slide{Deploying security}

\begin{quote}{\bf
Security is a process, not a product.} Products provide some protection, but the only way to effectively do business in an insecure world is to put processes in place that recognize the inherent insecurity in the products. The trick is to reduce your risk of exposure regardless of the products or patches.
\end{quote}
Source: \link{https://www.schneier.com/essays/archives/2000/04/the_process_of_secur.html}

Today, we will consider the deployment plan being:
\begin{list2}
\item People -- make sure management is on board, Sources -- which data to gather,
\item Technology -- select SIEM, architecture, tools and products
\item Dashboards -- we have done parts of this, refer to SOC book also
\item Procedures -- left as a home exercise today
\end{list2}



\slide{People: Data Analysis Skills}

\begin{quote}
Although we could spend an entire book creating an exhaustive list of skills needed to be a good security data scientist, this chapter covers the following skills/domains that a data scientist will benefit from
knowing within information security:
\begin{list2}
\item Domain expertise—Setting and maintaining a purpose to the analysis
\item Data management—Being able to prepare, store, and maintain data
\item Programming—The glue that connects data to analysis
\item Statistics—To learn from the data
\item Visualization—Communicating the results effectively
\end{list2}
It might be easy to label any one of these skills as the most important, but in reality, the whole is greater than the sum of its parts. Each of these contributes a significant and important piece to the workings of
security data science.
\end{quote}

Source: \emph{Data-Driven Security: Analysis, Visualization and Dashboards} Jay Jacobs, Bob Rudis\\
ISBN: 978-1-118-79372-5 February 2014 \url{https://datadrivensecurity.info/} - short DDS



\slide{People: Get management buy-in}

\hlkimage{6cm}{margarida-csilva-121801-unsplash.jpg}

You will probably need help from:

\begin{list2}
\item Buy-in from management, for requesting resources
\item Network and security departments -- getting data, opening ports
\item Application developers, web site programmers
\end{list2}
Lifeguard training photo by Margarida CSilva on Unsplash


\slide{Sources: Network overview without SIEM}

\hlkimage{15cm}{sample-ip-network.pdf}

\begin{quote}

\end{quote}

\begin{list2}
\item Internet, routers, firewalls, switches, clients and servers (Wi-Fi not shown)
\end{list2}


\slide{Sources: Strategy for implementing identification and detection}

We recommend that the following strategy is used for implementing identification and detection -- logging:
\begin{enumerate}
\item[\faSquareO] Enable system logging from servers
\item[\faSquareO] Enable system logging from network devices
\item[\faSquareO] Enable logging from client devices
\item[\faSquareO] Centralize logging
\item[\faSquareO] Add search facilities and dashboards
\item[\faSquareO] Perform system audits manually or automatically
\item[\faSquareO] Setup alerting and notification with procedures
\end{enumerate}

\slide{Extended Sources}
When a basic logging infrastructure is setup, it can be expanded to increase coverage, by
adding more sources:

\begin{list2}
\item DNS query logging -- will enable multiple cases to be resolved, example malware identification and tracing, when was a malware domain queried, when was the first infection
\item Web proxy logging -- which web pages did which client access
\item Session data from Firewalls, Netflow -- traffic patterns can be investigated and both attacks and cases like exfiltration can likely be seen

\end{list2}

Hint: Take the sources available first, make a proof-of-concept, expand coverage





\slide{Architecture: Tools}

%\hlkimage{}{}

\begin{quote}

\end{quote}

We will use the tools presented during the course:
\begin{list2}
\item Elastic stack: Elasticsearch, Logstash, Kibana, Filebeat, Packetbeat
\item Zeek and Suricata can easily be added at a later stage
\item Likewise DNS and web proxy logging could be added
\end{list2}

\vskip 1cm

The setup discussed here would be a good proof of conccept, and be valuable almost immediately

\slide{Elasticsearch}

\hlkimage{6cm}{demo-siem-setup-elasticsearch.pdf}


\begin{list2}
\item We plan to build a basic cluster with Elasticsearch, latest stable
\item Multiple ES nodes for easier upgrade, redundancy and performance
\item Each have 200Gb disk and 16Gb memory allocated
\end{list2}




\slide{Logstash -- syslog and SNMP trap receiver}

\hlkimage{6cm}{demo-siem-setup-logstash.pdf}

\begin{list2}
\item We have network devices which can only send syslog and SNMP trap -- \emph{push events from the network}
\item So enable inputs: snmptrap, tcp, udp and use UFW to redirect ports
\item We have made two servers, which use VRRP to have a common address
\end{list2}

\slide{Packetbeat}

\hlkimage{10cm}{demo-siem-setup-packetbeat.pdf}


\begin{list2}
\item By installing packetbeat and doing network mirroring from the network switch, we can gather a lot of information
\item Packetbeat supports Elastic Common Schema (ECS) \link{https://www.elastic.co/beats/packetbeat}
\item ICMP (v4 and v6)
DHCP (v4)
DNS
HTTP
AMQP 0.9.1
Cassandra
Mysql
PostgreSQL
Redis
Thrift-RPC
MongoDB
Memcache
NFS
TLS
SIP/SDP (beta)
\end{list2}


\slide{Application servers}

\hlkimage{3cm}{demo-siem-setup-servers.pdf}

\begin{quote}

\end{quote}

\begin{list2}
\item We told the server and application people to use Filebeat and Syslog
\item The Linux people decided to use syslog
\item Windows servers use Filebeat \link{}https://www.elastic.co/beats/filebeat
\item All of them send to the Logstash instances
\end{list2}

\slide{Baseline}

\hlkimage{10cm}{nfsen-ddos-profile-1.png}

\begin{list2}
\item Picture from NFsen running a specific profile to catch attacks
\item When you have a running system, it will start to gather a baseline
\item Comparing data from various times become possible, and usefull
\item The best baseline is from running the actual systems and services for an extended \emph{learning} period
\end{list2}

\slide{Alerting}

%\hlkimage{}{}

\begin{quote}\small
We’re excited to announce a new alerting framework that delivers a first-class alerting experience natively within the SIEM, Uptime, APM, and Metrics applications as part of the Kibana 7.7 release.

Alerting is a fundamental use case across the Elastic Stack, which is why we’re making it part of the core experience within Kibana. Whether you are monitoring application transactions or tracking brute force login attempts, our goal is to provide a tailored experience that allows you to build powerful alerts in the normal flow of your task. The new alerting framework is built from the ground up and designed to offer more than just convenient interfaces. We understand the need to go beyond just notifying people which is why we’ve also incorporated the ability to trigger predefined actions that can do anything from sending an email to using brand new third-party integrations with platforms like Slack and PagerDuty.

The new alerting framework is being introduced as a beta in the 7.7 release of Kibana and is available immediately on the Elasticsearch Service on Elastic Cloud, or for download.
\end{quote}

\begin{list2}
\item {\footnotesize\link{https://www.elastic.co/blog/introducing-the-new-alerting-framework-for-observability-security-and-the-elastic-stack}}
\item {\footnotesize\link{https://www.elastic.co/what-is/kibana-alerting}}
\item {\footnotesize\link{https://www.elastic.co/blog/alerting-in-the-elastic-stack}}
\end{list2}


\slide{Alerting everywhere}

%\hlkimage{}{}

\begin{quote}
Alerting everywhere: Kibana 7.7 introduces ubiquitous alerting for Elastic Observability, Elastic Security, and the Elastic Stack. Users can now create alerts directly from within the SIEM, APM, Metrics, and Uptime applications as well as for any index.
\end{quote}

\begin{list2}
\item Seems a lot has happened with alerting in the new version!
\item Lets try to work with the alerting framework, note: sending email can sometimes be tricky without some configuration.
\end{list2}

\exercise{ex:es7-alerting}

\slide{Common task: Elasticsearch Upgrades!}

%\hlkimage{}{}

\begin{quote}
Should we try upgrading to next major version of ES?\\
\link{https://www.elastic.co/blog/whats-new-elastic-8-0-0}
\end{quote}

How would we proceed
\begin{list2}
\item Make a backup, clone the VM
\item Update repositories, ansible or manually (we only have on cluster node)
\item Shut down ES, easy since only one node
\item Upgrade software and start again -- this will update the data on that node!
\end{list2}

Extra steps are needed when upgrading larger clusters. You should definitely try upgrading before going into production. Better if you have multiple clusters, test/staging and production.

\slide{ES reporting}

%\hlkimage{}{}

\begin{quote}{\bf
Push a button, get a report. Easy.}\\
Kibana is a fantastic way to visualize and explore your Elasticsearch data. Its reporting features let you easily export your favorite Kibana visualizations and dashboards. Each report is print-optimized, customizable, and PDF-formatted. And the option to add your own logo will give your reports the branded, polished look that will color your team impressed.
\end{quote}
Source: \link{https://www.elastic.co/what-is/kibana-reporting}


\begin{list2}
\item Not sure I agree, but some features are available
\item Discussion! Writing and presenting are two very different things, so are dashboards and reports!
\end{list2}


\slide{Automating Report Generation}

\begin{quote}{\bf
Create a POST URL}\\
Create the POST URL that triggers a report to generate.
\end{quote}
Source: \link{https://www.elastic.co/guide/en/kibana/current/automating-report-generation.html}


\begin{list2}
\item Not sure I agree, but some features are available
\item I like the automated report generation, getting data pushed from ES is a great feature.
\item Correlation also added
\link{https://www.elastic.co/blog/whats-new-elastic-security-7-10-0-correlation-cloud-visibility-detection}

\end{list2}



\slide{Automatic reporting: tcpflow}

\hlkimage{8cm}{simpsong-tcpflow.png}

\begin{list2}
  \item \link{https://github.com/simsong/tcpflow}
  \item \emph{Passive TCP Reconstruction and Forensic Analysis with tcpflow}, Simson Garfinkel and Michael Shick, Naval Postgraduate School Technical Report NPS-CS-13-003, September 2013.
  \link{https://calhoun.nps.edu/handle/10945/36026}
\end{list2}



\slide{Another route perhaps?}

We could also look at how others prepare their processes, using their SIEM etc.

Browse chapter 1 from Practical Threat Intelligence, Valentina Palacín

\emph{Practical Threat Intelligence and Data-Driven Threat Hunting}
Valentina Palacín, 2021, ISBN: 978-1-83855-637-2

\begin{list2}
\item Chapter 1: What Is Cyber Threat Intelligence?
\item Why this book?! It is about Mitre ATT\&CK framework and it has been in Humble Bundles, so if it shows up again, buy it
\item This book is very much hands on with lots of links, references, tools and names
\item I will now present a bit from the book, since you don't have it
\end{list2}


\slide{Investigate links}

\begin{list2}
\item We cannot go through all of it, but we can get inspired
\item Since this came from real actors, campaigns, threats it is mostly what a real case would be
\end{list2}

This will lead to the later part, doing \emph{an investigation}


\slide{Investigate links 1: OSSEM}

%\hlkimage{}{}

\begin{quote}
OSSEM: To help with the heavy work of creating data dictionaries, the Rodriguez
brothers created the Open Source Security Events Metadata (OSSEM) for
documenting and standardizing security event logs. The project is open source and
can be accessed through the project's GitHub repository\\
\url{https://github.com/hunters-forge/OSSEM}.
\end{quote}


\slide{Investigate links 2: Threat Hunter Playbook}

%\hlkimage{}{}

\begin{quote}
The Threat Hunter Playbook: This open source project is maintained by the
Rodriguez brothers and is meant to help with the documentation project and
sharing threat hunting concepts, developing certain techniques, and building
the hypothesis. You can read more about it in the project's GitHub repository\\
\url{https://github.com/hunters-forge/ThreatHunter-Playbook}
\end{quote}

\slide{Investigate links 3: Adversary emulation}

%\hlkimage{}{}

\begin{quote}
Emulating the adversary: Adversary emulation is a way for red teamers to
replicate adversary behaviors in their organization's environments. In order to
do that, the adversary behaviors need to be mapped and the techniques used by
them need to be chained together to create an action plan. The MITRE ATT\&CK™
Framework provides an example of how to create an emulation plan based on APT3\\
\url{https://attack.mitre.org/resources/adversary-emulation-plans/}
\end{quote}

\slide{MITRE Adversary Emulation Plans}

\hlkimage{10cm}{Mitre-APT3_phase_diagram.png}

\begin{quote}
To showcase the practical use of ATT\&CK for offensive operators and defenders, MITRE created Adversary Emulation Plans. These are prototype documents of what can be done with publicly available threat reports and ATT\&CK.
\end{quote}
Source: \url{https://attack.mitre.org/resources/adversary-emulation-plans/}



\slide{Investigate links 4: Mordor dataset}

%\hlkimage{}{}

\begin{quote}
Mordor: For this stage of the hunt, the Rodriguez brothers created the Mordor
project, which provides
"pre-recorded security events generated by simulated adversarial techniques" in
JSON format.\\
 \url{https://github.com/hunters-forge/mordor}
\end{quote}



\slidenext{}


\end{document}
